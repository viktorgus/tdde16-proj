{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TDDE16 Algos.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE4nm4Z4gzgV"
      },
      "source": [
        "# Evaluation of Unsupervised Extractive Text Summarization algorithms\r\n",
        "## Using word embeddings (BERT vs TFIDF)\r\n",
        "- LSA top-n sentences with largest top-n topic weights\r\n",
        "- LSA with weighted score\r\n",
        "- Textrank\r\n",
        "- Matchsum-like (Greedy document similarity maximizer of average document- vs average sentence embeddings)\r\n",
        "- K-means of sentence embeddings\r\n",
        "\r\n",
        "## Baselines\r\n",
        "- Lead\r\n",
        "- Oracle\r\n",
        "- Random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X2sXW7_WqHY"
      },
      "source": [
        "!pip install transformers\r\n",
        "!pip install sentencepiece\r\n",
        "!pip install tensorflow\r\n",
        "!pip install tensorflow_datasets \r\n",
        "!pip install spacy\r\n",
        "!python -m spacy download en_core_web_lg\r\n",
        "!pip install sentence_transformers\r\n",
        "!pip install rouge-score\r\n",
        "!pip install datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF-msHP96Trr"
      },
      "source": [
        "\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "import spacy \r\n",
        "import numpy as np\r\n",
        "from sentence_transformers import SentenceTransformer, util\r\n",
        "from datasets import load_dataset\r\n",
        "import scipy\r\n",
        "from rouge_score import rouge_scorer\r\n",
        "import networkx as nx\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.cluster import KMeans\r\n",
        "from sklearn.metrics import pairwise_distances_argmin_min\r\n",
        "import numpy as np\r\n",
        "import random\r\n",
        "\r\n",
        "n_sentences = 2\r\n",
        "\r\n",
        "sbert = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\r\n",
        "nlp = spacy.load(\"en_core_web_lg\")\r\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\")\r\n",
        "\r\n",
        "\r\n",
        "txt = \"\"\" This happened when we first started dating.\r\n",
        "His mobile used to ping and light up when someone texted him and once I saw that someone had texted him with the name \"Babe ❤️\" I didn't think of it as anything and that I had not seen it correctly but next coming weeks I saw it happening many times. He would get really happy when the person texted, used to smile really big and all. I started thinking I was being cheated on, the last straw for me was when the person texted \"love you too\" I confronted him about and he stared at me for some time before he started laughing.\r\n",
        "I cried because what the hell, so he calmed me down and explained to me that Babe is his grandmother, her name is Baberuth and everyone in the family called her Babe, she recently had gotten her first smartphone and he had taught her to text, so when she texted it was exciting for him to see her using emojis and stuff.\r\n",
        "Never felt so embarrassed in my life. A few months later he took me to meet her and I kid you not, for a 85 year old Babe is a sport. Seeing her punch a guy square in the jaw for harassing was a sight. We are best friends now. \"\"\"\r\n",
        "\r\n",
        "summary = \"\"\"I assumed my boyfriend was cheating on me but it was just his grandmother texting him.\"\"\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OK8a0ckXlx0u"
      },
      "source": [
        "# Baselines and Metrics\r\n",
        "- Getting sentences\r\n",
        "- Rouge scores\r\n",
        "- Oracle\r\n",
        "- Lead\r\n",
        "- Random Summary\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49o1IuOuF0Ea"
      },
      "source": [
        "\r\n",
        "def get_sentences(txt):\r\n",
        "  if isinstance(txt, list):\r\n",
        "    return(txt)\r\n",
        "  \r\n",
        "  doc = nlp(txt) \r\n",
        "  sentences = []\r\n",
        "  for sent in doc.sents:\r\n",
        "      sentences.append(\" \".join([token.text for token in sent]))\r\n",
        "  return(sentences)\r\n",
        "\r\n",
        "def rouge_scores(pred, summary, scores = ['rouge1', 'rouge2', 'rougeL'], scorer = None):\r\n",
        "  if scorer == None:\r\n",
        "    scorer = rouge_scorer.RougeScorer(scores, use_stemmer=True)\r\n",
        "  scores = scorer.score(pred, summary)\r\n",
        "  return [float(\"{:.4f}\".format(s.fmeasure)) for k, s in scores.items()]\r\n",
        "\r\n",
        "def oracle(txt, summary, maximize_score = 'rouge2'):\r\n",
        "  assert maximize_score in ['rouge1', 'rouge2', 'rougeL']\r\n",
        "  def get_summary(sentence_idx_list):\r\n",
        "      sorted_summary = sorted(sentence_idx_list, key = lambda x : x[0])\r\n",
        "      current_summary = \". \".join([entry[1] for entry in sorted_summary])\r\n",
        "      return(current_summary)\r\n",
        "\r\n",
        "  sentences = get_sentences(txt)\r\n",
        "  best_sentences = []\r\n",
        "  best_summary = \"\"\r\n",
        "  if n_sentences >= len(sentences):\r\n",
        "    return(\" \".join(sentences))\r\n",
        "  while len(best_sentences) < n_sentences:\r\n",
        "    scores = []\r\n",
        "    for idx, sent in enumerate(sentences):\r\n",
        "      current_summary = get_summary(best_sentences + [[idx, sent]])\r\n",
        "      scores.append(rouge_scores(current_summary, summary, [maximize_score])[0])\r\n",
        "    best_s_idx = np.argmax(scores)\r\n",
        "    best_sentences.append([best_s_idx, sentences.pop(best_s_idx)])\r\n",
        "  return(get_summary(best_sentences))\r\n",
        "\r\n",
        "\r\n",
        "def lead(txt):\r\n",
        "  sentences = get_sentences(txt)\r\n",
        "  if n_sentences>=len(sentences):\r\n",
        "    top_sentences = sentences\r\n",
        "  else:\r\n",
        "    top_sentences = sentences[0:n_sentences]\r\n",
        "\r\n",
        "  return(\". \".join(top_sentences))\r\n",
        "\r\n",
        "def rand(txt):\r\n",
        "  sentences = get_sentences(txt)\r\n",
        "  if n_sentences>=len(sentences):\r\n",
        "    top_sentences = sentences\r\n",
        "  else:\r\n",
        "    indexes = random.sample(range(0, len(sentences)), n_sentences)\r\n",
        "    indexes.sort()\r\n",
        "    top_sentences = [sentences[ind] for ind in indexes]\r\n",
        "  return(\". \".join(top_sentences))\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djZGjLRcl-g0"
      },
      "source": [
        "# LSA Summary\r\n",
        "- Non-Weighted\r\n",
        "- Weighted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZ_MSpoiy4mP",
        "outputId": "610083c9-bdec-48d5-985e-7f3c4e0bb933"
      },
      "source": [
        "\r\n",
        "def LSA_summary(txt, embedding_function):  \r\n",
        "  sentences = get_sentences(txt)\r\n",
        "  if n_sentences>=len(sentences):\r\n",
        "    top_sentences = sentences\r\n",
        "  else:\r\n",
        "    # Word x Sentence Matrix\r\n",
        "    sentence_embedding_matrix = embedding_function(sentences)\r\n",
        "    k = min(max(6,n_sentences),min(sentence_embedding_matrix.shape))\r\n",
        "    U, sigma, V = scipy.sparse.linalg.svds(sentence_embedding_matrix, which=\"LM\", k=k)\r\n",
        "    top_sentences = []\r\n",
        "    ind2ind = [i for i in range(len(sentences))]\r\n",
        "    for i in range(1,1+n_sentences):\r\n",
        "      best_sentence = np.argmax(V[-i,:])\r\n",
        "      sentence_idx = ind2ind[best_sentence]\r\n",
        "      top_sentences.append([sentence_idx, sentences[sentence_idx]])\r\n",
        "      # remove the sentence column and adjust indexes\r\n",
        "      V = np.delete(V, best_sentence, axis=1)\r\n",
        "      ind2ind.pop(best_sentence)\r\n",
        "    top_sentences.sort(key =  lambda x: x[0])\r\n",
        "    top_sentences = [x[1] for x in top_sentences]\r\n",
        "\r\n",
        "  return(\". \".join(top_sentences))\r\n",
        "\r\n",
        "def LSA_summary_weighted(txt, embedding_function):\r\n",
        "  sentences = get_sentences(txt)\r\n",
        "  if n_sentences>=len(sentences):\r\n",
        "    top_sentences = sentences\r\n",
        "  else:\r\n",
        "    # Word x Sentence Matrix\r\n",
        "    sentence_embedding_matrix = embedding_function(sentences)\r\n",
        "    k = min(max(6,n_sentences),min(sentence_embedding_matrix.shape))\r\n",
        "    U, sigma, V = scipy.sparse.linalg.svds(sentence_embedding_matrix, which=\"LM\", k=k)\r\n",
        "    sentence_scores = np.sqrt(np.square(sigma) @ np.square(V))\r\n",
        "    sentence_scores_idx = [[i,sentence_scores[i]] for i in range(len(sentence_scores))]\r\n",
        "    sentence_scores_idx.sort(key = lambda x:x[1])\r\n",
        "    top_sentences_idx_score = sentence_scores_idx[-1:-(n_sentences+1):-1]\r\n",
        "    top_sentences_idx_score.sort(key =  lambda x: x[0])\r\n",
        "    top_sentences = [sentences[x[0]] for x in top_sentences_idx_score]\r\n",
        "\r\n",
        "  return(\". \".join(top_sentences))\r\n",
        "\r\n",
        "def LSA_TFIDF(txt, weighted = False):\r\n",
        "  embedding_function = lambda sentences: np.transpose(tfidf_vectorizer.fit_transform(sentences))\r\n",
        "  if weighted:\r\n",
        "    return(LSA_summary_weighted(txt, embedding_function))\r\n",
        "  else:\r\n",
        "    return(LSA_summary(txt, embedding_function))\r\n",
        "\r\n",
        "def LSA_BERT(txt, weighted = False):\r\n",
        "  embedding_function = lambda sentences: np.transpose(np.array([sbert.encode(sentence, convert_to_numpy=True) for sentence in sentences]))\r\n",
        "  if weighted:\r\n",
        "    return(LSA_summary_weighted(txt, embedding_function))\r\n",
        "  else:\r\n",
        "    return(LSA_summary(txt, embedding_function))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "weighted = True\r\n",
        "lead_summary = lead(txt)\r\n",
        "oracle_summary = oracle(txt, summary)\r\n",
        "lsa_tfidf_summary = LSA_TFIDF(txt, weighted=weighted)\r\n",
        "lsa_bert_summary = LSA_BERT(txt, weighted=weighted)\r\n",
        "\r\n",
        "lead_score = rouge_scores(lead_summary, summary)\r\n",
        "oracle_score = rouge_scores(oracle_summary, summary)\r\n",
        "lsa_tfidf_scores = rouge_scores(lsa_tfidf_summary, summary)\r\n",
        "lsa_bert_score = rouge_scores(lsa_bert_summary, summary)\r\n",
        "\r\n",
        "print(f\"LEAD SUMMARY: Score:{lead_score} txt:{lead_summary}\")\r\n",
        "print(f\"ORACLE SUMMARY: Score:{oracle_score} txt:{oracle_summary}\")\r\n",
        "print(f\"TFIDF SUMMARY: Score:{lsa_tfidf_scores} txt:{lsa_tfidf_summary}\")\r\n",
        "print(f\"BERT SUMMARY: Score:{lsa_bert_score} txt:{lsa_bert_summary}\")\r\n",
        "print(f\"REAL SUMMARY: {summary}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LEAD SUMMARY: Score:[0.1714, 0.0606, 0.1714] txt:  This happened when we first started dating . \n",
            ". His mobile used to ping and light up when someone texted him\n",
            "ORACLE SUMMARY: Score:[0.25, 0.087, 0.1667] txt:His mobile used to ping and light up when someone texted him. I cried because what the hell , so he calmed me down and explained to me that Babe is his grandmother\n",
            "TFIDF SUMMARY: Score:[0.2069, 0.0, 0.1379] txt:I saw it happening many times .. Never felt so embarrassed in my life .\n",
            "BERT SUMMARY: Score:[0.1481, 0.0, 0.1481] txt:I saw it happening many times .. We are best friends now .\n",
            "REAL SUMMARY: I assumed my boyfriend was cheating on me but it was just his grandmother texting him.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BMwbXezmHaQ"
      },
      "source": [
        "# TextRank "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKgtmomWFE15",
        "outputId": "13298ba7-990c-4ea6-bd9c-a1efbe65d91e"
      },
      "source": [
        "\r\n",
        "def pagerank(M, num_iterations: int = 100, d: float = 0.85):\r\n",
        "\r\n",
        "    # Row normalization\r\n",
        "    #sum_of_rows = M.sum(axis=1)\r\n",
        "    #M = M / sum_of_rows[:, np.newaxis]\r\n",
        "    N = M.shape[1]\r\n",
        "    v = np.random.rand(N, 1)\r\n",
        "    v = v / np.linalg.norm(v, 1)\r\n",
        "    M_hat = (d * M + (1 - d) / N)\r\n",
        "    for i in range(num_iterations):\r\n",
        "        v = M_hat @ v\r\n",
        "    return v\r\n",
        "\r\n",
        "def textrank_summary(txt, sentence_similarity, embedding_function):\r\n",
        "\r\n",
        "  sentences = get_sentences(txt)\r\n",
        "  encoded_sentences = embedding_function(sentences)\r\n",
        "  n = len(sentences)\r\n",
        "  similarity_matrix = np.zeros((n, n))\r\n",
        "  for idx1 in range(n):\r\n",
        "        for idx2 in range(n):\r\n",
        "            if not idx1==idx2:\r\n",
        "              similarity_matrix[idx1][idx2] = sentence_similarity(encoded_sentences[idx1], encoded_sentences[idx2])\r\n",
        "  scores = pagerank(similarity_matrix, 100, 0.85)\r\n",
        "\r\n",
        "  # Sort over textrank scores\r\n",
        "  ranked_sentences = sorted(((scores[i],i,s) for i,s in enumerate(sentences)), reverse=True)    \r\n",
        "  top_sentences = ranked_sentences[0:n_sentences]\r\n",
        "  # Sort over ordering for readability\r\n",
        "  top_sentences.sort(key = lambda x:x[1])\r\n",
        "\r\n",
        "  summary = \". \".join([s[2] for s in top_sentences])\r\n",
        "  return(summary)\r\n",
        "\r\n",
        "def textrank_BERT(txt):\r\n",
        "    sentence_similarity = lambda s1, s2: util.pytorch_cos_sim(s1, s2)\r\n",
        "    embedding_function = lambda sentences: [sbert.encode(s, convert_to_tensor=True) for s in sentences]\r\n",
        "    return(textrank_summary(txt, sentence_similarity, embedding_function))\r\n",
        "\r\n",
        "def textrank_TFIDF(txt):\r\n",
        "    sentence_similarity = lambda s1, s2: 1-scipy.spatial.distance.cosine(s1,s2)\r\n",
        "    embedding_function = lambda sentences: tfidf_vectorizer.fit_transform(sentences).toarray()\r\n",
        "    return(textrank_summary(txt, sentence_similarity, embedding_function))\r\n",
        "\r\n",
        "textrank_tfidf_summary = textrank_TFIDF(txt)\r\n",
        "textrank_bert_summary = textrank_BERT(txt)\r\n",
        "textrank_tfidf_scores = rouge_scores(textrank_tfidf_summary, summary)\r\n",
        "textrank_bert_score = rouge_scores(textrank_bert_summary, summary)\r\n",
        "\r\n",
        "print(f\"TFIDF SUMMARY: Score:{textrank_tfidf_scores} txt:{textrank_tfidf_summary}\")\r\n",
        "print(f\"BERT SUMMARY: Score:{textrank_bert_score} txt:{textrank_bert_summary}\")\r\n",
        "print(f\"REAL SUMMARY: {summary}\")\r\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TFIDF SUMMARY: Score:[0.32, 0.0833, 0.28] txt:and once I saw that someone had texted him with the name \" Babe ❤ ️. I started thinking I was being cheated on , the last straw for me was when the person texted \" love you too \"\n",
            "BERT SUMMARY: Score:[0.2642, 0.0392, 0.2642] txt:He would get really happy when the person texted , used to smile really big and all .. I started thinking I was being cheated on , the last straw for me was when the person texted \" love you too \"\n",
            "REAL SUMMARY: I assumed my boyfriend was cheating on me but it was just his grandmother texting him.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6RS6FE7mMtE"
      },
      "source": [
        "# Matchsum-U"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMfinlrvlzBB",
        "outputId": "a5d786a6-e54c-4019-9464-cc65e1a14a68"
      },
      "source": [
        "# compare average sentence embedding to document sentence embedding and pick iteratively sentences that moves closest.\r\n",
        "def matchsum(txt, similarity_function, embedding_function):\r\n",
        "  sentences = get_sentences(txt)\r\n",
        "  \r\n",
        "  sentence_embeddings = embedding_function(sentences)\r\n",
        "  document_embedding = sum(sentence_embeddings)/len(sentence_embeddings)\r\n",
        "  best_sentences = []\r\n",
        "  while len(best_sentences)<n_sentences:\r\n",
        "    similarities = []\r\n",
        "    if best_sentences == []:\r\n",
        "      current_embeddings = []\r\n",
        "    else:\r\n",
        "      current_embeddings = [s[2] for s in best_sentences]\r\n",
        "    for emb in sentence_embeddings:\r\n",
        "      potential_embedding = sum([emb] + current_embeddings)/(len(current_embeddings)+1)\r\n",
        "      similarities.append(similarity_function(potential_embedding, document_embedding))\r\n",
        "    best_sentence_idx = np.argmax(similarities)\r\n",
        "    best_sentences.append([best_sentence_idx,sentences[best_sentence_idx],sentence_embeddings[best_sentence_idx]])\r\n",
        "  best_sentences.sort(key=lambda x:x[0])\r\n",
        "  summary = \". \".join([s[1] for s in best_sentences])\r\n",
        "  return(summary)\r\n",
        "\r\n",
        "\r\n",
        "def matchsum_BERT(txt):\r\n",
        "  similarity_function = lambda s1, s2: 1-scipy.spatial.distance.cosine(s1,s2)\r\n",
        "  embedding_function = lambda sentences: [sbert.encode(s, convert_to_numpy=True) for s in sentences]\r\n",
        "  return(matchsum(txt, similarity_function, embedding_function))\r\n",
        "\r\n",
        "def matchsum_TFIDF(txt):\r\n",
        "  similarity_function = lambda s1, s2: 1-scipy.spatial.distance.cosine(s1,s2)\r\n",
        "  embedding_function = lambda sentences: tfidf_vectorizer.fit_transform(sentences).toarray()\r\n",
        "  return(matchsum(txt, similarity_function, embedding_function))\r\n",
        "        \r\n",
        "\r\n",
        "matchsum_summary_bert = matchsum_BERT(txt)\r\n",
        "matchsum_summary_tfidf = matchsum_TFIDF(txt)\r\n",
        "matchsum_tfidf_scores = rouge_scores(matchsum_summary_tfidf, summary)\r\n",
        "matchsum_bert_score = rouge_scores(matchsum_summary_bert, summary)\r\n",
        "\r\n",
        "print(f\"TFIDF SUMMARY: Score:{matchsum_tfidf_scores} txt:{matchsum_summary_tfidf}\")\r\n",
        "print(f\"BERT SUMMARY: Score:{matchsum_bert_score} txt:{matchsum_summary_bert}\")\r\n",
        "print(f\"REAL SUMMARY: {summary}\")\r\n",
        "  "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TFIDF SUMMARY: Score:[0.32, 0.0833, 0.28] txt:and once I saw that someone had texted him with the name \" Babe ❤ ️. I started thinking I was being cheated on , the last straw for me was when the person texted \" love you too \"\n",
            "BERT SUMMARY: Score:[0.3721, 0.0488, 0.3256] txt:I saw it happening many times .. I started thinking I was being cheated on , the last straw for me was when the person texted \" love you too \"\n",
            "REAL SUMMARY: I assumed my boyfriend was cheating on me but it was just his grandmother texting him.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Elx2WEPamPkj"
      },
      "source": [
        "# Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHsLqgjW78LP",
        "outputId": "e9549754-695c-4eae-b65c-20931b99c026"
      },
      "source": [
        "\r\n",
        "def cluster_summary(txt, similarity_function, embedding_function):\r\n",
        "  sentences = get_sentences(txt)\r\n",
        "  encoded = embedding_function(sentences)\r\n",
        "\r\n",
        "  kmeans = KMeans(n_clusters=n_sentences)\r\n",
        "  kmeans = kmeans.fit(encoded)\r\n",
        "  avg = []\r\n",
        "  for j in range(n_sentences):\r\n",
        "      idx = np.where(kmeans.labels_ == j)[0]\r\n",
        "      avg.append(np.mean(idx))\r\n",
        "  closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, encoded)\r\n",
        "  ordering = sorted(range(n_sentences), key=lambda k: avg[k])\r\n",
        "  summary = '. '.join([sentences[closest[idx]] for idx in ordering])\r\n",
        "  return(summary)\r\n",
        "\r\n",
        "def cluster_TFIDF(txt):\r\n",
        "  similarity_function = lambda s1, s2: 1-scipy.spatial.distance.cosine(s1,s2)\r\n",
        "  embedding_function = lambda sentences: tfidf_vectorizer.fit_transform(sentences).toarray()\r\n",
        "  return(cluster_summary(txt, similarity_function, embedding_function))\r\n",
        "\r\n",
        "def cluster_BERT(txt):\r\n",
        "  similarity_function = lambda s1, s2: 1-scipy.spatial.distance.cosine(s1,s2)\r\n",
        "  embedding_function = lambda sentences: [sbert.encode(s, convert_to_numpy=True) for s in sentences]\r\n",
        "  return(cluster_summary(txt, similarity_function, embedding_function))\r\n",
        "\r\n",
        "cluster_summary_bert = cluster_BERT(txt)\r\n",
        "cluster_summary_tfidf = cluster_TFIDF(txt)\r\n",
        "cluster_tfidf_scores = rouge_scores(cluster_summary_tfidf, summary)\r\n",
        "cluster_bert_score = rouge_scores(cluster_summary_bert, summary)\r\n",
        "\r\n",
        "print(f\"TFIDF SUMMARY: Score:{cluster_tfidf_scores} txt:{cluster_summary_tfidf}\")\r\n",
        "print(f\"BERT SUMMARY: Score:{cluster_bert_score} txt:{cluster_summary_bert}\")\r\n",
        "print(f\"REAL SUMMARY: {summary}\")\r\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TFIDF SUMMARY: Score:[0.32, 0.0833, 0.32] txt:I started thinking I was being cheated on , the last straw for me was when the person texted \" love you too \". and once I saw that someone had texted him with the name \" Babe ❤ ️\n",
            "BERT SUMMARY: Score:[0.2979, 0.0444, 0.2979] txt:I started thinking I was being cheated on , the last straw for me was when the person texted \" love you too \". A few months later he took me to meet her\n",
            "REAL SUMMARY: I assumed my boyfriend was cheating on me but it was just his grandmother texting him.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd_GCV2qmRih"
      },
      "source": [
        "# Saving results to G-Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJxIKiqfSKkN",
        "outputId": "96ec1ff9-8f88-4bd4-c138-094767043ebb"
      },
      "source": [
        "import datetime\r\n",
        "import json\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')\r\n",
        "\r\n",
        "def save_results_gdrive(score_data):\r\n",
        "  current_time = datetime.datetime.now()  \r\n",
        "  file_name = f\"Results{current_time}\"\r\n",
        "\r\n",
        "  score_avg = score_data.copy()\r\n",
        "  for key in score_avg.keys():\r\n",
        "    if isinstance(score_avg[key], list):\r\n",
        "      score_avg[key] = np.mean(np.array(score_avg[key]), axis=0)\r\n",
        "      score_avg[key].tolist()\r\n",
        "\r\n",
        "  class NumpyEncoder(json.JSONEncoder):\r\n",
        "      \"\"\" Special json encoder for numpy types \"\"\"\r\n",
        "      def default(self, obj):\r\n",
        "          if isinstance(obj, np.integer):\r\n",
        "              return int(obj)\r\n",
        "          elif isinstance(obj, np.floating):\r\n",
        "              return float(obj)\r\n",
        "          elif isinstance(obj, np.ndarray):\r\n",
        "              return obj.tolist()\r\n",
        "          return json.JSONEncoder.default(self, obj)\r\n",
        "  print(score_avg)\r\n",
        "  dumped = json.dumps(score_avg, cls=NumpyEncoder)\r\n",
        "\r\n",
        "  with open(f'/content/gdrive/MyDrive/Colab Notebooks/{file_name}.json', 'w') as fp:\r\n",
        "      json.dump(dumped, fp)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJrcHx25mXLL"
      },
      "source": [
        "# Test Script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUckVnS9XmoK"
      },
      "source": [
        "from tqdm import tqdm\r\n",
        "import warnings\r\n",
        "\r\n",
        "warnings.filterwarnings(action='once')\r\n",
        "save_interval = 50\r\n",
        "data_name = 'cnn_dailymail'\r\n",
        "dataset = load_dataset(data_name, '3.0.0')\r\n",
        "test_data = dataset['test']\r\n",
        "weighted = False\r\n",
        "\r\n",
        "score_data = {'dataset': data_name, 'n_sentences':n_sentences,\r\n",
        "             'weighted_lsa': weighted,\r\n",
        "              'tfidf_cluster':[], 'bert_cluster':[], \r\n",
        "              'tfidf_matchsum':[], 'bert_matchsum':[],\r\n",
        "              'tfidf_textrank':[], 'bert_textrank':[],\r\n",
        "              'tfidf_lsa':[], 'bert_lsa':[],\r\n",
        "              'oracle':[], 'lead':[], 'random':[]}\r\n",
        "\r\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\r\n",
        "\r\n",
        "def test_baselines(sentences, gold_summary, scorer = None):\r\n",
        "  lead_summary = lead(sentences)\r\n",
        "  oracle_summary = oracle(sentences, gold_summary)\r\n",
        "  rand_summary = rand(sentences)\r\n",
        "  lead_score = rouge_scores(lead_summary, gold_summary, scorer = scorer)\r\n",
        "  oracle_score = rouge_scores(oracle_summary, gold_summary, scorer = scorer)\r\n",
        "  rand_score = rouge_scores(rand_summary, gold_summary)\r\n",
        "  score_data['oracle'].append(oracle_score)\r\n",
        "  score_data['lead'].append(lead_score)\r\n",
        "  score_data['random'].append(rand_score)\r\n",
        "\r\n",
        "def test_lsa(sentences, gold_summary, scorer = None):\r\n",
        "  lsa_tfidf_summary = LSA_TFIDF(sentences, weighted=weighted)\r\n",
        "  lsa_bert_summary = LSA_BERT(sentences, weighted=weighted)\r\n",
        "  lsa_tfidf_scores = rouge_scores(lsa_tfidf_summary, gold_summary, scorer = scorer)\r\n",
        "  lsa_bert_score = rouge_scores(lsa_bert_summary, gold_summary, scorer = scorer)\r\n",
        "  score_data['tfidf_lsa'].append(lsa_tfidf_scores)\r\n",
        "  score_data['bert_lsa'].append(lsa_bert_score)\r\n",
        "\r\n",
        "def test_matchsum(sentences, gold_summary, scorer = None):\r\n",
        "  matchsum_summary_bert = matchsum_BERT(sentences)\r\n",
        "  matchsum_summary_tfidf = matchsum_TFIDF(sentences)\r\n",
        "  matchsum_tfidf_scores = rouge_scores(matchsum_summary_tfidf, gold_summary, scorer = scorer)\r\n",
        "  matchsum_bert_score = rouge_scores(matchsum_summary_bert, gold_summary, scorer = scorer)\r\n",
        "  score_data['tfidf_matchsum'].append(matchsum_tfidf_scores)\r\n",
        "  score_data['bert_matchsum'].append(matchsum_bert_score)\r\n",
        "\r\n",
        "def test_textrank(sentences, gold_summary, scorer = None):\r\n",
        "  textrank_tfidf_summary = textrank_TFIDF(sentences)\r\n",
        "  textrank_bert_summary = textrank_BERT(sentences)\r\n",
        "  textrank_tfidf_scores = rouge_scores(textrank_tfidf_summary, gold_summary, scorer = scorer)\r\n",
        "  textrank_bert_score = rouge_scores(textrank_bert_summary, gold_summary, scorer = scorer)\r\n",
        "  score_data['tfidf_textrank'].append(textrank_tfidf_scores)\r\n",
        "  score_data['bert_textrank'].append(textrank_bert_score)\r\n",
        "\r\n",
        "\r\n",
        "def test_cluster(sentences, gold_summary, scorer = None):\r\n",
        "  cluster_summary_bert = cluster_BERT(sentences)\r\n",
        "  cluster_summary_tfidf = cluster_TFIDF(sentences)\r\n",
        "  cluster_tfidf_scores = rouge_scores(cluster_summary_tfidf, gold_summary, scorer = scorer)\r\n",
        "  cluster_bert_score = rouge_scores(cluster_summary_bert, gold_summary, scorer = scorer)\r\n",
        "  score_data['tfidf_cluster'].append(cluster_tfidf_scores)\r\n",
        "  score_data['bert_cluster'].append(cluster_bert_score)\r\n",
        "\r\n",
        "\r\n",
        "for i in tqdm(range(len(test_data))):\r\n",
        "  text = test_data[i]['article']\r\n",
        "  gold_summary = test_data[i]['highlights']\r\n",
        "  sentences = get_sentences(text)\r\n",
        "  if len(sentences) > 60:\r\n",
        "    continue\r\n",
        "\r\n",
        "  test_functions = [test_baselines, test_lsa, test_matchsum, test_textrank, test_cluster]\r\n",
        "  for summary_task in test_functions:\r\n",
        "    try:\r\n",
        "      summary_task(sentences, gold_summary, scorer)\r\n",
        "    except ValueError as e:\r\n",
        "      print(e)\r\n",
        "  if i % save_interval == 0:\r\n",
        "    save_results_gdrive(score_data)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpXsg-ZHP8cV"
      },
      "source": [
        "Display previous results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePKecJE2k7hQ",
        "outputId": "9d8a644a-83ee-4a1f-d9f9-62f894329ca0"
      },
      "source": [
        "file_name = 'At-Home-Results-1-Weighted'\r\n",
        "with open(f'/content/gdrive/MyDrive/Colab Notebooks/{file_name}.json', 'r') as fp:\r\n",
        "    print(json.load(fp))\r\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"dataset\": \"cnn_dailymail\", \"n_sentences\": 1, \"weighted_lsa\": true, \"tfidf_lsa\": [0.18607097334878334, 0.061866888760139155, 0.13962882387022058], \"bert_lsa\": [0.08258093858632673, 0.020380272305909584, 0.06550648899188838]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APSRVq4Urg6u"
      },
      "source": [
        "Sources used:\r\n",
        "\r\n",
        "[Non-Deep Learning methods](https://medium.com/jatana/unsupervised-text-summarization-using-sentence-embeddings-adb15ce83db1)\r\n",
        "\r\n",
        "[List of SOTA](http://nlpprogress.com/english/summarization.html)\r\n",
        "\r\n",
        "[Extractive text with BERT (MATCHSUM) ](https://arxiv.org/pdf/2004.08795.pdf)\r\n",
        "\r\n",
        "[LSA](https://www.researchgate.net/publication/220195824_Text_summarization_using_Latent_Semantic_Analysis)\r\n",
        "\r\n",
        "\r\n",
        "[ROUGE](https://www.aclweb.org/anthology/W04-1013.pdf)\r\n",
        "\r\n",
        "[Textrank](https://towardsdatascience.com/understand-text-summarization-and-create-your-own-summarizer-in-python-b26a9f09fc70)\r\n",
        "\r\n",
        "[Oracle (under extractive training)](https://arxiv.org/pdf/1611.04230.pdf\r\n",
        ")\r\n",
        "\r\n",
        "\r\n",
        "[TextRank](https://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf\r\n",
        ")\r\n",
        "\r\n"
      ]
    }
  ]
}